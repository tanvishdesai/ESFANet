Paper_ID,Title,Year,Authors,DOI_or_Link,Dataset_Used,FL_Variant,NonIID_Handling,Aggregation_Method,Loss_Function,Transfer_Learning,Privacy_Mechanism,Compression_Efficiency,Key_Metrics,Precision_at_Threshold,NonIID_Performance_Gap,Gaps_Limitations,Relevance_Score,Notes_Quotes
1,"Cluster Based Secure Multi-Party Computation in Federated Learning for Histopathology Images",2022,"Hosseini et al.","arXiv:2208.10919v1","TCGA (Lung Cancer: LUAD, LUSC)","Cluster-based FL (SMC)","Clustering hospitals based on similarity/availability; implicitly handles some heterogeneity","Summation within clusters via SMC, then server averaging","Cross Entropy (implied for classification)","DenseNet121 (pretrained) + MIL Attention","Secure Multi-Party Computation (SMC)","Negative impact: Higher communication overhead due to SMC exchanges","Accuracy, F1-Score","N/A","N/A (Focuses on privacy vs accuracy trade-off)","Focuses on encryption (SMC) rather than statistical heterogeneity (skew) or precision-focused loss (FedAlert). High comms cost unlike your Top-K compression.",7,"p.8: 'Proposed method performs close to the baseline, surpassing DP... at cost of higher communication overhead.'"
2,"Advancing breast, lung and prostate cancer research with federated learning. A systematic review",2025,"Ankolekar et al.","10.1038/s41746-025-01591-5","Systematic Review (25 studies: TCGA, private, etc.)","Review of various (FedAvg, FedProx, FedNova)","Review of methods (FedProx, FedDyn) handling statistical heterogeneity","Review of Federated Averaging and Consensus models","Various (Standard ML losses)","Review of ResNet, UNet, DenseNet, Large Pre-trained models","Review of DP, SMC, Homomorphic Encryption","Noted as a challenge (bandwidth limitations)","Accuracy, AUC, Dice (for segmentation)","N/A","Varies by study reviewed","It is a survey, not an implementation. Validates the need for FedProx and Transfer Learning but lacks a specific novel algorithm to compare against your Consensus Aggregation.",8,"p.7: 'FedProx may be promising for heterogeneous oncology data... regularises the local objective function.'"
3,"Colorectal Cancer Histopathological Grading using Multi-Scale Federated Learning",2025,"Arafath et al.","arXiv:2511.03693v1","CRC-HGD (Colorectal Cancer)","FedProx","FedProx used specifically to mitigate client drift from heterogeneous distributions","FedAvg logic stabilized by Proximal term","Cross Entropy + Proximal Term (mu=0.01)","ResNetRS50 (Dual-stream: 224px and 320px)","Standard FL privacy (data remains local)","Not explicitly addressed","Accuracy, Recall, Precision, F1","Precision: 79.2% for Grade III (High risk)","+1.9% Accuracy gain over centralized model","Uses FedProx (like your code) but lacks the specific 'FedAlert' penalty for False Positives. Focuses on multi-scale inputs rather than consensus aggregation.",9,"p.8: 'FedProx minimized client divergence, ensuring smooth convergence.' (Matches your config.FEDPROX_MU usage)"
4,"FedDP: Privacy-preserving method based on federated learning for histopathology image segmentation",2024,"Pan et al.","arXiv:2411.04509v1","WSSS4LUAD (Lung Cancer Segmentation)","FedAvg + Differential Privacy (FedDP)","Mentions heterogeneity issues but focuses on gradient inversion attacks","Weighted Averaging with Gaussian Noise added to updates","Segmentation Loss (Dice/Jaccard based)","Swin Transformer / ConvNeXt","Differential Privacy (Gaussian Noise, epsilon budget)","Not explicitly addressed","Dice, Jaccard, Accuracy","N/A (Segmentation task)","~0.5% drop in accuracy due to DP noise","Task is Segmentation, yours is Classification. Good reference for your DP implementation (Gaussian noise), but lacks the 'Alert' and 'Consensus' logic.",8,"p.6: 'Larger standard deviation increases noise... stronger privacy protection but potentially impacting data accuracy.'"
5,"Scaling Federated Learning Solutions with Kubernetes for Synthesizing Histopathology Images",2025,"Preda et al.","arXiv:2504.04130v1","TCGA-CRC-DX (Colorectal Cancer)","FedAvg (applied to GANs)","Simulated Class Imbalance (Non-IID ratio 0.6 - 0.9)","FedAvg","GAN Adversarial Loss","ACGAN + ViT Discriminator","FL architecture (keeping data local)","Not addressed (focus on infrastructure/Kubernetes)","FID (Image Quality), F1-Score (Downstream classification)","F1: ~0.88 (Baseline) vs ~0.91 (Synthetic Augmentation)","Results similar to centralized setting even with imbalance","Focuses on Generative models (GANs) and Infrastructure (Kubernetes), not direct classification optimization. Lacks your specific loss/aggregation innovations.",6,"p.9: 'We call this scenario the not independent and identically distributed (non-IID) and study the effect of class imbalance.'"
6,"Simplified Swarm Learning Framework for Robust and Scalable Diagnostic Services in Cancer Histopathology",2025,"Wu et al.","arXiv:2504.16732v1 [cs.DC]","10,000 annotated histopathology images (augmented via Macenko normalization)","Peer-to-Peer Swarm Learning (P2P-SL) without Blockchain","Simulated scarcity and imbalance: Node 0 held 10% data; Node 2 down-sampled to 25%.","Dynamic peer-to-peer synchronization; Weighted averaging based on validation threshold (80%)","Standard Loss (implied via AUC/F1 metrics); Focus is on architecture (DenseNet decoders)","TorchXRayVision pre-trained model + LoRA adapters + DenseNet decoder","TLS/SSL encryption for peer communication; Localized training","LoRA-adapter weight exchange (lightweight) via gRPC","AUC=0.6892 (Swarm) vs 0.7156 (Centralized); Precision/Recall analyzed","N/A (Uses standard AUC/F1, does not specify high-threshold precision)","~3% drop in AUC compared to Centralized; 80% recovery of performance vs standalone","Highly relevant for histopathology. GAP: Lacks the false-positive penalty (FedAlert) and consensus aggregation present in your code. Decentralized nature contrasts with your server-client model.",8,"p.2: 'Eliminating blockchain dependencies... integration of optimized pre-trained models such as TorchXRayVision'"
7,"PathFL: Multi-Alignment Federated Learning for Pathology Image Segmentation",2025,"Zhang et al.","arXiv:2505.22522v1 [cs.CV]","4 sets: CoNSeP, CPM17, CRAG, CryoNuSeg (Cross-source, modality, organ, scanner)","PathFL (Three-level alignment: Image, Feature, Aggregation)","Addressed via 'Collaborative Style Enhancement' (mean/std exchange) and 'Adaptive Feature Alignment'.","Stratified Similarity Aggregation (SSA) - layer-wise cosine similarity re-weighting","Cross Entropy Loss","U-Net, ViT, CONCH, CHIEF backbones","Standard FL (gradients only); Vicinal Risk Minimization (VRM)","Implicit efficiency via statistical feature exchange (mean/variance) instead of raw data","Dice Score (84.27% average); ASSD","N/A (Focuses on Segmentation overlap/Dice)","PathFL improves Dice by ~1.65% to ~7.94% over FedAvg in heterogeneous settings","Strong relevance for 'Consensus' mechanisms (uses cosine similarity like your code). GAP: Focuses on Segmentation, not Classification. Does not use Focal/Alert loss.",9,"p.8: 'Stratified similarity aggregation... weights are aggregated layer by layer based on similarity evaluation interaction.'"
8,"Federated Learning for the Classification of Tumor Infiltrating Lymphocytes",2022,"Baid et al.","arXiv:2203.16622v2 [eess.IV]","TCGA (12 anatomical sites), 50x50 micron patches","Standard FedAvg (simulated via OpenFL)","Natural Non-IID via Data Sharding by Anatomy (e.g., Site 1=Cervix, Site 2=Lung)","FedAvg (Weight Averaging)","Categorical Cross-Entropy","VGG16 pre-trained on ImageNet","Standard FL (Model updates only)","None specified","Balanced Classification Accuracy (0.89 consensus vs 0.75 centralized)","N/A (Uses Balanced Accuracy)","Surprising result: FL Consensus (0.89) outperformed Centralized (0.75) due to better generalization.","Direct baseline for your project. Uses older VGG16 and standard FedAvg. GAP: Your solution's MobileNetV2 + FedAlert + Consensus should be more efficient and precise.",7,"p.6: 'The federated consensus model performed better than the individual sites... and centralized.'"
9,"Federated Learning with Research Prototypes for Multi-Center MRI-based Detection of Prostate Cancer",2022,"Rajagopal et al.","arXiv:2206.05617v1 [cs.CV]","UCSF and UCLA Prostate MRI (1800+ exams)","FedSGD (via NVFlare)","Real-world institutional differences (UCSF vs UCLA scanners/protocols)","Gradient Averaging (FedSGD)","Multi-task: Dice + Weighted BCE + Histogram Suppression","UCNet (Custom 3D Residual UNet)","NVFlare security features; Data/Model abstraction layers","N/A (Focus on software framework 'FLtools')","Intersection-over-Union (IoU), Binary Classification Accuracy","N/A","FL increased classification accuracy by 9.5% - 14.8% over local training.","Focuses on MRI (not histopathology) and framework architecture (NVFlare). GAP: Your code focuses on algorithmic logic (loss/agg), this focuses on deployment engineering.",5,"p.4: 'Separates model development and FL implementation code... NVFlare toolkit.'"
10,"Federated learning and differential privacy for medical image analysis",2022,"Adnan, M. et al.","10.1038/s41598-022-05539-7","TCGA (Lung Cancer Histopathology)","FedAvg with DP-SGD","Simulated by varying patient counts and cancer sub-types across 4 clients","Standard FedAvg (Weighted Average)","Cross-Entropy (implied for MIL)","DenseNet (feature extractor) + Attention-based MIL","RÃ©nyi Differential Privacy (epsilon=2.90)","None explicitly mentioned","Accuracy: 0.824 (IID), 0.824 (Non-IID); strong privacy guarantees","N/A (Focus on Accuracy)","No gap observed in their specific simulation (Non-IID performed equal to IID)","Focuses heavily on privacy (DP) but uses basic FedAvg; does not address false positive penalties or communication compression.",7,"p.6: 'FedAvg achieves comparable performance to centralized training without explicitly sharing private data.'"
11,"Improving Performance of Federated Learning based Medical Image Analysis in Non-IID Settings using Image Augmentation",2021,"Cetinkaya, A. et al.","10.1109/UBMK52708.2021.9558913","Chest X-Ray (COVID-19, Pneumonia, etc.)","FedAvg + FedAug (Proposed Augmentation)","Dirichlet distribution (alpha=1 for high skew, alpha=2 for low skew)","Standard FedAvg","Cross-Entropy","Custom CNN (5 conv layers)","None","None","Accuracy increased from 83.22% to 89.43% with augmentation","N/A","~6% drop from IID (89.22%) to Non-IID (83.22%) without mitigation","Relies solely on data augmentation to fix non-IID; does not use advanced aggregation or specific loss functions for class imbalance.",6,"p.5: 'The non-IID data brought significant increase in performance issues... proposed method alleviated the degradation.'"
12,"Federated Learning for Medical Image Classification: A Comprehensive Benchmark",2025,"Zhou, Z. et al.","arXiv:2504.05238v1","9 Datasets including ColonPath, TB (Real-world Non-IID), Retina, Breast","FedAvg, FedProx, MOON, FedNova, DENSE","Real-world heterogeneity (TB dataset) and Dirichlet simulations","Benchmark of various methods; Proposed: DDPM-based augmentation","Cross-Entropy; FedProx adds L2 regularization; MOON adds contrastive loss","ResNet-50","None (DENSE allows data-free One-Shot, preserving privacy implicitly)","DENSE (One-shot) reduces comms; Others standard","TB Dataset Accuracy: FedAvg (86.6%), Proposed DDPM (88.4%)","N/A (Top-1 Accuracy focus)","TB Dataset: FedAvg converges slower and lower than IID baselines","Comprehensive benchmark but solution is computationally heavy (Training Diffusion Models on clients); lacks focus on high-precision alert systems.",8,"p.9: 'No single federated learning algorithm consistently delivers optimal performance across all medical federated learning scenarios.'"
13,"(Proposed Solution)",2025,"Your Code (fdl-2.py)","N/A (Source Code)","PatchCamelyon (PCam)","FedAlert + FedProx + Consensus","Dirichlet (Scenario A: alpha=10, B: alpha=1, C: alpha=0.5)","Multi-stage: FedAlert-score weighting + Consensus (Cosine Similarity) blending","FedAlertLoss (Focal Loss + Soft Threshold Penalty for FPs/FNs)","MobileNetV2 (Pretrained on ImageNet, fine-tuned)","None (Configurable placeholders present)","Top-K Sparsification (Ratio 0.3)","Precision/Recall at Alert Threshold (0.75)","High focus on Precision at 0.75 threshold","Explicitly targets 'Alert' scenarios where False Positives are costly; combines Communication Efficiency with specialized Loss; fills the 'Precision' gap in literature.",10,"Config: 'FEDALERT_ALPHA = 6.0 ... to heavily penalize false positives and aggressively aim for higher precision.'"